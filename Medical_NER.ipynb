{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ospv6uB5T07j",
        "outputId": "f6a4db93-b553-4a1a-bad3-be672638b881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPM0Rb_Su5jJ",
        "outputId": "11d50e1c-c315-433b-856a-c0e451889be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 16 08:36:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0             33W /   70W |    3606MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iDdAH84XYQ1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "class Preprocessing_Maccrobat:\n",
        "    def __init__(self, dataset_folder, tokenizer):\n",
        "        # Tạo list lưu các file id\n",
        "        self.file_ids = [f.split(\".\")[0] for f in os.listdir(dataset_folder) if f.endswith('.txt')]\n",
        "\n",
        "        # Tạo list lưu các file .txt, .ann\n",
        "        self.text_files = [f+\".txt\" for f in self.file_ids]\n",
        "        self.anno_files = [f+\".ann\" for f in self.file_ids]\n",
        "\n",
        "        # Số lượng file cần xử lý\n",
        "        self.num_samples = len(self.file_ids)\n",
        "\n",
        "        # Lấy ra tất cả các câu được lưu trong các file text (.txt)\n",
        "        self.texts: List[str] = []\n",
        "\n",
        "        for i in range(self.num_samples):\n",
        "            file_path = os.path.join(dataset_folder, self.text_files[i])\n",
        "            with open(file_path, \"r\") as f:\n",
        "                self.texts.append(f.read())\n",
        "\n",
        "        # Lấy ra tất cả các term, mỗi term sẽ có các thông tin như label, term, start, end\n",
        "        self.tags: List[Dict[str: str]] = []\n",
        "        for i in range(self.num_samples):\n",
        "            file_path = os.path.join(dataset_folder, self.anno_files[i])\n",
        "            with open(file_path, \"r\") as f:\n",
        "                text_bound_ann = [t.split(\"\\t\") for t in f.read().split(\"\\n\") if t.startswith(\"T\")]\n",
        "                text_bound_lst = []\n",
        "                for text_b in text_bound_ann:\n",
        "                    label = text_b[1].split(\" \")\n",
        "                    try:\n",
        "                        _ = int(label[1])\n",
        "                        _ = int(label[2])\n",
        "                        tag = {\n",
        "                            \"text\": text_b[-1],\n",
        "                            \"label\": label[0],\n",
        "                            \"start\": label[1],\n",
        "                            \"end\": label[2]\n",
        "                        }\n",
        "                        text_bound_lst.append(tag)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                self.tags.append(text_bound_lst)\n",
        "\n",
        "        # Tokenizer\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    # Tạo phương thức process():\n",
        "    # 1. Đọc file .txt => extract full text\n",
        "    # 2. Đọc file .ann => lấy ra các tags (các entity)\n",
        "    # 3. Tìm những text có label (có nhãn) -> label_offset (tạo phương thức riêng để xử lý)\n",
        "    # 4. Tìm những text không có label (không có nhãn) -> zero_offset (tạo phương thức riêng để xử lý)\n",
        "    # 5. Gộp label_offset và zero_offset theo thứ tự vị trí (tạo phương thức riêng để xử lý)\n",
        "    #       Nếu zero xuất hiện trước -> _add_zero -> thêm \"O\"\n",
        "    #       Nếu label xuất hiện trước -> _add_label -> thêm \"B-\" (Begin) và \"I-\" (Inside)\n",
        "    # 6. Kết quả: tokens + labels\n",
        "\n",
        "    # Ví dụ: kết quả thu được sau khi dùng phương thức process()\n",
        "    # tokens = [\"Patient\", \"has\", \"head\", \"##ache\", \"and\", \"fe\", \"##ver\", \".\"]\n",
        "    # labels = [\"O\", \"O\", \"B-Symptom\", \"I-Symptom\", \"O\", \"B-Symptom\", \"I-Symptom\", \"O\"]\n",
        "    def process(self):\n",
        "        # Khai báo list input_texts: danh sách các câu đã được tokenize\n",
        "        input_texts = []\n",
        "        # Khai báo input_labels: danh sách nhãn B - I - O tương ứng\n",
        "        input_labels = []\n",
        "\n",
        "        # Lặp qua từng file id cần được xử lý\n",
        "        for idx in range(self.num_samples):\n",
        "            # 1. Đọc file .txt => extract full text\n",
        "            full_text = self.texts[idx]\n",
        "            # 2. Đọc file .ann => lấy ra các tags (các entity)\n",
        "            tags = self.tags[idx]\n",
        "\n",
        "            # 3. Khai báo label_offset: danh sách các đoạn có label\n",
        "            label_offset = []\n",
        "            # Khai báo continuous_label_offset: gộp tất cả các offset (text) có label -> để tìm vùng không có label\n",
        "            continuous_label_offset = []\n",
        "            for tag in tags:\n",
        "                offset = list(range(int(tag[\"start\"]), int(tag[\"end\"]) + 1))\n",
        "                label_offset.append(offset)\n",
        "                continuous_label_offset.extend(offset)\n",
        "\n",
        "            all_offset = list(range(len(full_text)))\n",
        "            # zero_offset: các vị trí không có label -> chuyển thành các đoạn liên tục (find_continuous_range)\n",
        "            zero_offset = [offset for offset in all_offset if offset not in continuous_label_offset]\n",
        "            zero_offset = Preprocessing_Maccrobat.find_continuous_range(zero_offset)\n",
        "\n",
        "            # 5. Khởi tạo danh sách token (các câu) và label (nhãn) tương ứng cho mỗi offdet trong câu\n",
        "            self.tokens = []\n",
        "            self.labels = []\n",
        "            # Chúng ta cần phương thức _merge_offset để gộp label_offset và zero_offset lại theo thứ tự\n",
        "            self._merge_offset(full_text, tags, zero_offset, label_offset)\n",
        "\n",
        "            input_texts.append(self.tokens)\n",
        "            input_labels.append(self.labels)\n",
        "\n",
        "        return input_texts, input_labels\n",
        "\n",
        "\n",
        "    def _merge_offset(self, full_text, tags, zero_offset, label_offset):\n",
        "        # zero: [[0, 1, 2], [6, 7]] label: [[3, 4, 5]] => [[0, 1, 2, 3, 4, 5, 6, 7], [10, 11, 12, 13, 14]]\n",
        "        i = j = 0\n",
        "        # So sánh vị trí bắt đầu của vùng không label và có label\n",
        "        # Ưu tiên thêm vùng xuất hiện trước trong văn bản\n",
        "        while i < len(zero_offset) and j < len(label_offset):\n",
        "            if zero_offset[i][0] < label_offset[j][0]:\n",
        "                self._add_zero(full_text, zero_offset, i)\n",
        "                i += 1\n",
        "            else:\n",
        "                self._add_label(full_text, label_offset, j, tags)\n",
        "                j += 1\n",
        "\n",
        "        # Thêm các vùng còn lại (nếu có)\n",
        "        while i < len(zero_offset):\n",
        "            self._add_zero(full_text, zero_offset, i)\n",
        "            i += 1\n",
        "\n",
        "        while j < len(label_offset):\n",
        "            self._add_label(full_text, label_offset, j, tags)\n",
        "            j += 1\n",
        "\n",
        "\n",
        "    # Code phương thức _add_zero() - Thêm vùng không có label\n",
        "    def _add_zero(self, full_text, offset, index):\n",
        "        start, *_, end = offset[index] if len(offset[index]) > 1 else (offset[index][0], offset[index][0] + 1)\n",
        "        text = full_text[start:end]\n",
        "        text_tokens = self.tokenizer.tokenize(text)\n",
        "\n",
        "        self.tokens.extend(text_tokens)\n",
        "        self.labels.extend(\n",
        "            [\"O\"] * len(text_tokens)\n",
        "        )\n",
        "\n",
        "    # Code phương thức _add_label() - Thêm vùng có label\n",
        "    def _add_label(self, full_text, offset, index, tags):\n",
        "        start, *_, end = offset[index] if len(offset[index]) > 1 else (offset[index][0], offset[index][0] + 1)\n",
        "        text = full_text[start:end]\n",
        "        text_tokens = self.tokenizer.tokenize(text)\n",
        "\n",
        "        self.tokens.extend(text_tokens)\n",
        "        # \"headache\" -> tokenize thành [\"head\", \"##ache\"] -> nhãn: [\"B-Symptom\", \"I-Symptom\"]\n",
        "        self.labels.extend(\n",
        "            [f\"B-{tags[index][\"label\"]}\"] + [f\"I-{tags[index][\"label\"]}\"] * (len(text_tokens) - 1)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def build_label2id(tokens: List[List[str]]):\n",
        "        label2id = {}\n",
        "        id_counter = 0\n",
        "        for token in [token for sublist in tokens for token in sublist]:\n",
        "            if token not in label2id:\n",
        "                label2id[token] = id_counter\n",
        "                id_counter += 1\n",
        "        return label2id\n",
        "\n",
        "    # Chuyển thành các đoạn liên tục\n",
        "    # [0, 1, 2, 6, 7] => zero_offset = [[0, 1, 2], [6, 7]], label_offset = [3, 4, 5]\n",
        "    @staticmethod # Khai báo phương thức là staticmethod => không cần đưa tham số self vào (vì đây là phương thức độc lập nhưng nằm trong class)\n",
        "    def find_continuous_range(data): # [0, 1, 2, 6, 7]\n",
        "        if not data:\n",
        "            return []\n",
        "        ranges = []\n",
        "        start = data[0]\n",
        "        prev = data[0]\n",
        "\n",
        "        for number in data[1:]: # [1, 2, 6, 7]\n",
        "            if number != prev + 1: # Mất đi tính liên tục\n",
        "                ranges.append(list(range(start, prev + 1)))\n",
        "                start = number\n",
        "            prev = number\n",
        "        ranges.append(list(range(start, prev + 1)))\n",
        "        return ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-um_1Cca7tT"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GgFfcrbu5jN"
      },
      "outputs": [],
      "source": [
        "dataset_folder = r\"/content/drive/MyDrive/Cybersoft/NLP & LLM/NLP_03/Resource/MACCROBAT2020\"\n",
        "\n",
        "Maccrobat_builder = Preprocessing_Maccrobat(dataset_folder, tokenizer)\n",
        "input_texts, input_labels = Maccrobat_builder.process()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxNmgAjau5jN"
      },
      "outputs": [],
      "source": [
        "label2id = Preprocessing_Maccrobat.build_label2id(input_labels)\n",
        "id2label = {v: k for k, v in label2id.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH2h7ha3u5jO"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "injpGmc4u5jP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_train, input_val, labels_train, labels_val = train_test_split(\n",
        "    input_texts,\n",
        "    input_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbXa-mY3u5jQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "MAX_LEN = 512\n",
        "\n",
        "class NER_Dataset(Dataset):\n",
        "    def __init__(self, input_texts, input_labels, tokenizer, label2id, max_len=MAX_LEN):\n",
        "        super().__init__()\n",
        "        self.tokens = input_texts\n",
        "        self.labels = input_labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label2id = label2id\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Lấy tokens và labels dựa vào index\n",
        "        input_token = self.tokens[idx]\n",
        "        # Chuyển label từ string sang index dùng label2id\n",
        "        label_token = [self.label2id[label] for label in self.labels[idx]]\n",
        "\n",
        "        # Chuyển tokens sang input_ids dùng tokenizer\n",
        "        input_token = self.tokenizer.convert_tokens_to_ids(input_token)\n",
        "        attention_mask = [1] * len(input_token) # Model sẽ phải chú ý đến tất cả các token như nhau\n",
        "\n",
        "        input_ids = self.pad_and_truncate(input_token, pad_id=self.tokenizer.pad_token_id)\n",
        "        labels = self.pad_and_truncate(label_token, pad_id=0)\n",
        "        attention_mask = self.pad_and_truncate(attention_mask, pad_id=0)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.as_tensor(input_ids),\n",
        "            \"labels\": torch.as_tensor(labels),\n",
        "            \"attention_mask\": torch.as_tensor(attention_mask)\n",
        "        }\n",
        "\n",
        "\n",
        "    # Khai báo phương thức pad_and_truncate\n",
        "    # Thêm pad cho những câu ngắn, truncate (cắt) nếu câu quá dài\n",
        "    def pad_and_truncate(self, inputs, pad_id):\n",
        "        if len(inputs) < self.max_len: # Thêm pad (id của <pad>, pad_id)\n",
        "            padded_inputs = inputs + [pad_id] * (self.max_len - len(inputs))\n",
        "        else: # truncate\n",
        "            padded_inputs = inputs[:self.max_len]\n",
        "\n",
        "        return padded_inputs\n",
        "\n",
        "    def label2id(self, labels):\n",
        "        return [self.label2id[label] for label in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkC-OPHZu5jR"
      },
      "outputs": [],
      "source": [
        "train_set = NER_Dataset(input_train, labels_train, tokenizer, label2id)\n",
        "val_set = NER_Dataset(input_val, labels_val, tokenizer, label2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgMCDnOtu5jR"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INdcD3jAu5jR",
        "outputId": "708b0e2b-8934-409d-ac2d-6665fcdb6520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at d4data/biomedical-ner-all and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([84]) in the checkpoint and torch.Size([83]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([84, 768]) in the checkpoint and torch.Size([83, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"d4data/biomedical-ner-all\",\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsuUZ5KBzNHW",
        "outputId": "4daee799-2512-4fd2-b6fc-bda33c001e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForTokenClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=83, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxVxG_mqu5jS"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LslYWNTVu5jS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzPTJh8Du5jS"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    mask = labels != 0\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions[mask], references=labels[mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcJBVKOru5jS",
        "outputId": "0a2c0d8d-4ed5-4cbd-efa4-9983ba6d43a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/tmp/ipython-input-418047954.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"ner-biomedical-maccrobat2020\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=20,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    optim=\"adamw_torch\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "mKXcPBYQzTOE",
        "outputId": "7279767c-910d-4514-fd41-241ac22c9a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 12:45, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.638300</td>\n",
              "      <td>1.434759</td>\n",
              "      <td>0.437846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.295300</td>\n",
              "      <td>0.880317</td>\n",
              "      <td>0.625139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.847700</td>\n",
              "      <td>0.680408</td>\n",
              "      <td>0.721555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.620700</td>\n",
              "      <td>0.590564</td>\n",
              "      <td>0.760344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>0.543355</td>\n",
              "      <td>0.783524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.367500</td>\n",
              "      <td>0.547440</td>\n",
              "      <td>0.783986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.302000</td>\n",
              "      <td>0.551066</td>\n",
              "      <td>0.796269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.249200</td>\n",
              "      <td>0.547319</td>\n",
              "      <td>0.796731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.210800</td>\n",
              "      <td>0.546332</td>\n",
              "      <td>0.802180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.563673</td>\n",
              "      <td>0.805597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.156400</td>\n",
              "      <td>0.571000</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.138400</td>\n",
              "      <td>0.571989</td>\n",
              "      <td>0.807167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.124000</td>\n",
              "      <td>0.569777</td>\n",
              "      <td>0.805412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.110100</td>\n",
              "      <td>0.580434</td>\n",
              "      <td>0.807444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.103800</td>\n",
              "      <td>0.588822</td>\n",
              "      <td>0.810307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.093900</td>\n",
              "      <td>0.592028</td>\n",
              "      <td>0.806335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.089400</td>\n",
              "      <td>0.592443</td>\n",
              "      <td>0.806428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.086100</td>\n",
              "      <td>0.596645</td>\n",
              "      <td>0.808460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.083700</td>\n",
              "      <td>0.597178</td>\n",
              "      <td>0.807998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.081200</td>\n",
              "      <td>0.594789</td>\n",
              "      <td>0.807905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=0.41233884513378144, metrics={'train_runtime': 766.9392, 'train_samples_per_second': 4.172, 'train_steps_per_second': 0.261, 'total_flos': 418702245888000.0, 'train_loss': 0.41233884513378144, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt8XEszPu5jS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def inference(sentence, model, tokenizer, device=\"cuda\"):\n",
        "    # 1. Tokenize input với tokenizer chuẩn (trả về input_ids + attention_mask)\n",
        "    encoding = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    # 2. Dự đoán\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # 3. Lấy nhãn dự đoán (argmax)\n",
        "    preds = torch.argmax(logits, dim=-1).squeeze(0)  # [seq_len]\n",
        "\n",
        "    # 4. Map ids → labels\n",
        "    preds_labels = [model.config.id2label[p.item()] for p in preds]\n",
        "\n",
        "    # 5. Lấy token đã tokenize\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze(0))\n",
        "\n",
        "    return tokens, preds_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Hfcrelu5jS"
      },
      "outputs": [],
      "source": [
        "def merge_entity(tokens, preds_labels):\n",
        "    \"\"\"\n",
        "    tokens: list[str] - token đã tokenize (có thể có subword)\n",
        "    preds_labels: list[str] - nhãn dự đoán dạng \"B-Symptom\", \"I-Symptom\", \"O\"\n",
        "\n",
        "    Trả về: list[tuple(entity_type, text)]\n",
        "    \"\"\"\n",
        "    merged_list = []\n",
        "    temp_tokens = []\n",
        "    current_label = None\n",
        "\n",
        "    for token, label in zip(tokens, preds_labels):\n",
        "        # Lấy type thực sự (bỏ B-/I-), giữ O\n",
        "        type_label = label.split(\"-\")[-1]\n",
        "\n",
        "        if type_label == \"O\":\n",
        "            if temp_tokens:\n",
        "                merged_list.append((current_label, \" \".join(temp_tokens).replace(\" ##\", \"\")))\n",
        "                temp_tokens = []\n",
        "                current_label = None\n",
        "            merged_list.append((type_label, token.replace(\"##\", \"\")))\n",
        "        else:\n",
        "            if current_label == type_label:\n",
        "                temp_tokens.append(token)\n",
        "            else:\n",
        "                if temp_tokens:\n",
        "                    merged_list.append((current_label, \" \".join(temp_tokens).replace(\" ##\", \"\")))\n",
        "                temp_tokens = [token]\n",
        "                current_label = type_label\n",
        "\n",
        "    if temp_tokens:\n",
        "        merged_list.append((current_label, \" \".join(temp_tokens).replace(\" ##\", \"\")))\n",
        "\n",
        "    return merged_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w2yQsv9u5jS"
      },
      "outputs": [],
      "source": [
        "sentence = \"\"\"A 48 year - old female presented with vaginal bleeding and abnormal Pap smears .\n",
        "Upon diagnosis of invasive non - keratinizing SCC of the cervix ,\n",
        "she underwent a radical hysterectomy with salpingo - oophorectomy\n",
        "which demonstrated positive spread to the pelvic lymph nodes and the parametrium .\n",
        "Pathological examination revealed that the tumour also extensively involved the lower uterine segment .\n",
        "\"\"\"\n",
        "tokens, preds_labels = inference(sentence, model, tokenizer)\n",
        "results = merge_entity(tokens, preds_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS-Er2lsu5jT",
        "outputId": "1ae5e4c2-5bd6-4886-c506-619aa0ed2725"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('O', '[CLS]'),\n",
              " ('O', 'a'),\n",
              " ('Age', '48 year - old'),\n",
              " ('Sex', 'female'),\n",
              " ('Clinical_event', 'presented'),\n",
              " ('O', 'with'),\n",
              " ('Biological_structure', 'vaginal'),\n",
              " ('Sign_symptom', 'bleeding'),\n",
              " ('O', 'and'),\n",
              " ('Lab_value', 'abnormal'),\n",
              " ('Diagnostic_procedure', 'pa'),\n",
              " ('Sign_symptom', '##p'),\n",
              " ('O', 'sm'),\n",
              " ('O', 'ears'),\n",
              " ('O', '.'),\n",
              " ('O', 'upon'),\n",
              " ('O', 'diagnosis'),\n",
              " ('O', 'of'),\n",
              " ('Detailed_description', 'invasive non - keratinizing'),\n",
              " ('Disease_disorder', 'scc'),\n",
              " ('O', 'of'),\n",
              " ('O', 'the'),\n",
              " ('Biological_structure', 'cervi'),\n",
              " ('O', 'x'),\n",
              " ('O', ','),\n",
              " ('O', 'she'),\n",
              " ('O', 'underwent'),\n",
              " ('O', 'a'),\n",
              " ('Detailed_description', 'radical'),\n",
              " ('Therapeutic_procedure', 'hysterectomy'),\n",
              " ('O', 'with'),\n",
              " ('Therapeutic_procedure', 'salpingo - oophorectomy'),\n",
              " ('O', 'which'),\n",
              " ('O', 'demonstrated'),\n",
              " ('Lab_value', 'positive'),\n",
              " ('O', 'spread'),\n",
              " ('O', 'to'),\n",
              " ('O', 'the'),\n",
              " ('Biological_structure', 'pelvic lymph nodes'),\n",
              " ('O', 'and'),\n",
              " ('O', 'the'),\n",
              " ('Biological_structure', 'parametrium'),\n",
              " ('O', '.'),\n",
              " ('Diagnostic_procedure', 'pathological examination'),\n",
              " ('O', 'revealed'),\n",
              " ('O', 'that'),\n",
              " ('O', 'the'),\n",
              " ('Sign_symptom', 'tu'),\n",
              " ('O', 'mour'),\n",
              " ('O', 'also'),\n",
              " ('O', 'extensively'),\n",
              " ('O', 'involved'),\n",
              " ('O', 'the'),\n",
              " ('Biological_structure', 'lower ut'),\n",
              " ('O', 'erine'),\n",
              " ('O', 'segment'),\n",
              " ('O', '.'),\n",
              " ('O', '[SEP]')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "import evaluate\n",
        "import accelerate\n",
        "import sklearn\n",
        "\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"evaluate:\", evaluate.__version__)\n",
        "print(\"accelerate:\", accelerate.__version__)\n",
        "print(\"scikit-learn:\", sklearn.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyUOw5M3ztpb",
        "outputId": "6ff1a5d5-63d5-4664-e0b6-b3dd8bdae08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.8.0+cu126\n",
            "transformers: 4.57.1\n",
            "evaluate: 0.4.6\n",
            "accelerate: 1.11.0\n",
            "scikit-learn: 1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDodKx-Bu5jT",
        "outputId": "f082445d-088e-4470-be6b-604368b6d986"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./ner-biomedical-maccrobat2020-final/tokenizer_config.json',\n",
              " './ner-biomedical-maccrobat2020-final/special_tokens_map.json',\n",
              " './ner-biomedical-maccrobat2020-final/vocab.txt',\n",
              " './ner-biomedical-maccrobat2020-final/added_tokens.json',\n",
              " './ner-biomedical-maccrobat2020-final/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Lưu mô hình và tokenizer\n",
        "model_path = \"./ner-biomedical-maccrobat2020-final\"\n",
        "\n",
        "trainer.save_model(model_path)   # Lưu model + config + weights\n",
        "tokenizer.save_pretrained(model_path)  # Lưu tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "model.eval()\n",
        "model.to(\"cuda\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCtLuAnh3hJx",
        "outputId": "76b89c9f-1827-4ae0-ee4e-7fe0a11f7a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForTokenClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=83, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"\"\"A 48 year - old female presented with vaginal bleeding and abnormal Pap smears .\n",
        "Upon diagnosis of invasive non - keratinizing SCC of the cervix ,\n",
        "she underwent a radical hysterectomy with salpingo - oophorectomy\n",
        "which demonstrated positive spread to the pelvic lymph nodes and the parametrium .\n",
        "Pathological examination revealed that the tumour also extensively involved the lower uterine segment .\n",
        "\"\"\"\n",
        "tokens, preds_labels = inference(sentence, model, tokenizer)\n",
        "results = merge_entity(tokens, preds_labels)"
      ],
      "metadata": {
        "id": "IwpApHGo3-Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw2K2A2r4CHy",
        "outputId": "4301669a-45c4-4e2b-f0e1-3cab75dbc9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('O', '[CLS]'),\n",
              " ('O', 'a'),\n",
              " ('Age', '48 year - old'),\n",
              " ('Sex', 'female'),\n",
              " ('Clinical_event', 'presented'),\n",
              " ('O', 'with'),\n",
              " ('Biological_structure', 'vaginal'),\n",
              " ('Sign_symptom', 'bleeding'),\n",
              " ('O', 'and'),\n",
              " ('Lab_value', 'abnormal'),\n",
              " ('Diagnostic_procedure', 'pa'),\n",
              " ('Sign_symptom', '##p'),\n",
              " ('O', 'sm'),\n",
              " ('O', 'ears'),\n",
              " ('O', '.'),\n",
              " ('O', 'upon'),\n",
              " ('O', 'diagnosis'),\n",
              " ('O', 'of'),\n",
              " ('Detailed_description', 'invasive non - keratinizing'),\n",
              " ('Disease_disorder', 'scc'),\n",
              " ('O', 'of'),\n",
              " ('O', 'the'),\n",
              " ('Biological_structure', 'cervi'),\n",
              " ('O', 'x'),\n",
              " ('O', ','),\n",
              " ('O', 'she'),\n",
              " ('O', 'underwent'),\n",
              " ('O', 'a'),\n",
              " ('Detailed_description', 'radical'),\n",
              " ('Therapeutic_procedure', 'hysterectomy'),\n",
              " ('O', 'with'),\n",
              " ('Therapeutic_procedure', 'salpingo - oophorectomy'),\n",
              " ('O', 'which'),\n",
              " ('O', 'demonstrated'),\n",
              " ('Lab_value', 'positive'),\n",
              " ('O', 'spread'),\n",
              " ('O', 'to'),\n",
              " ('O', 'the'),\n",
              " ('Biological_structure', 'pelvic lymph nodes'),\n",
              " ('O', 'and'),\n",
              " ('O', 'the'),\n",
              " ('Biological_structure', 'parametrium'),\n",
              " ('O', '.'),\n",
              " ('Diagnostic_procedure', 'pathological examination'),\n",
              " ('O', 'revealed'),\n",
              " ('O', 'that'),\n",
              " ('O', 'the'),\n",
              " ('Sign_symptom', 'tu'),\n",
              " ('O', 'mour'),\n",
              " ('O', 'also'),\n",
              " ('O', 'extensively'),\n",
              " ('O', 'involved'),\n",
              " ('O', 'the'),\n",
              " ('Biological_structure', 'lower ut'),\n",
              " ('O', 'erine'),\n",
              " ('O', 'segment'),\n",
              " ('O', '.'),\n",
              " ('O', '[SEP]')]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Nén thư mục model thành file zip\n",
        "shutil.make_archive(\"ner-biomedical-maccrobat2020-final\", 'zip', \"./ner-biomedical-maccrobat2020-final\")\n",
        "\n",
        "# Tải file zip về máy\n",
        "files.download(\"ner-biomedical-maccrobat2020-final.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3FTE4iLm4Dqc",
        "outputId": "86001574-8f63-4374-9b1e-7b7d3b4c1bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1811c517-9a19-4117-9f46-99574d6ea2e9\", \"ner-biomedical-maccrobat2020-final.zip\", 245349840)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0sRqXql4Z7q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}